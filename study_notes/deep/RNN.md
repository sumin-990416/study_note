## ìˆœì„œê°€ ìžˆëŠ” ë°ì´í„°: ìˆœí™˜ ì‹ ê²½ë§ (RNN) âœï¸ðŸ“ˆ

**1. MLPì˜ í•œê³„ì™€ RNNì˜ ë“±ìž¥**

- MLP(êµì•ˆ 5)ëŠ” ëª¨ë“  ìž…ë ¥ì„ **'ì„œë¡œ ë…ë¦½ì '**ì´ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤.
    
- ì˜ˆë¥¼ ë“¤ì–´, "I am a boy"ë¼ëŠ” ë¬¸ìž¥ì„ MLPì— ë„£ìœ¼ë©´, "I", "am", "a", "boy"ê°€ ì„œë¡œ ì•„ë¬´ ê´€ê³„ê°€ ì—†ëŠ” 4ê°œì˜ ë°ì´í„°ë¼ê³  ë´…ë‹ˆë‹¤.
    
- í•˜ì§€ë§Œ **ìˆœì„œ**ê°€ ë°”ë€Œë©´ "boy am I a"ì²˜ëŸ¼ ì˜ë¯¸ê°€ ì™„ì „ížˆ ë‹¬ë¼ì§€ì£ .
    
- MLPëŠ” ì´ 'ìˆœì„œ' ì •ë³´ë¥¼ í•™ìŠµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸, ì£¼ê°€, ë‚ ì”¨ ë°ì´í„° ë“± **ìˆœì°¨ì ì¸(Sequential)** ë°ì´í„°ì— ë¶€ì í•©í•©ë‹ˆë‹¤.
    

**2. RNNì˜ í•µì‹¬ ì•„ì´ë””ì–´: 'ê¸°ì–µ' (Memory)**

- RNNì˜ ì•„ì´ë””ì–´ëŠ” ê°„ë‹¨í•©ë‹ˆë‹¤. "ì´ì „ ë‹¨ê³„ì˜ ì •ë³´ë¥¼ 'ê¸°ì–µ'í•´ì„œ ë‹¤ìŒ ë‹¨ê³„ì˜ ê³„ì‚°ì— í•¨ê»˜ ì‚¬ìš©í•˜ìž."
    
- ì´ 'ê¸°ì–µ'ì„ ì „ë¬¸ ìš©ì–´ë¡œ **ì€ë‹‰ ìƒíƒœ(Hidden State, $h_t$)**ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.
    
- RNNì€ ë§ˆì¹˜ ìžê¸° ìžì‹ ì—ê²Œë¡œ ëŒì•„ì˜¤ëŠ” ë£¨í”„(Loop)ë¥¼ ê°€ì§„ ì‹ ê²½ë§ìž…ë‹ˆë‹¤.
    
    - **1ë‹¨ê³„:** "I"($x_1$)ê°€ ë“¤ì–´ì˜¤ë©´, ê³„ì‚°ì„ í†µí•´ "ê¸°ì–µ 1"($h_1$)ì„ ë§Œë“­ë‹ˆë‹¤.
        
    - **2ë‹¨ê³„:** "am"($x_2$)ì´ ë“¤ì–´ì˜¤ë©´, ì´ $x_2$ì™€ **"ê¸°ì–µ 1"($h_1$)**ì„ í•¨ê»˜ ì‚¬ìš©í•´ "ê¸°ì–µ 2"($h_2$)ë¥¼ ë§Œë“­ë‹ˆë‹¤.
        
    - **3ë‹¨ê³„:** "a"($x_3$)ê°€ ë“¤ì–´ì˜¤ë©´, ì´ $x_3$ì™€ **"ê¸°ì–µ 2"($h_2$)**ë¥¼ í•¨ê»˜ ì‚¬ìš©í•´ "ê¸°ì–µ 3"($h_3$)ì„ ë§Œë“­ë‹ˆë‹¤.
        
- ì´ë ‡ê²Œ ë§¤ ë‹¨ê³„(time step)ë§ˆë‹¤ **ì´ì „ì˜ ê¸°ì–µ($h_{t-1}$)**ê³¼ **í˜„ìž¬ ìž…ë ¥($x_t$)**ì„ ë°›ì•„ **í˜„ìž¬ì˜ ê¸°ì–µ($h_t$)**ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    
- **ê°œë…ì  ìˆ˜ì‹:**
    
    - $h_t = \tanh(W_{hh} h_{t-1} + W_{xh} x_t + b_h)$
        
        - $h_t$ (í˜„ìž¬ ê¸°ì–µ)ëŠ” $h_{t-1}$ (ì´ì „ ê¸°ì–µ)ê³¼ $x_t$ (í˜„ìž¬ ìž…ë ¥)ë¥¼ ì¡°í•©í•˜ì—¬ ê³„ì‚°ë©ë‹ˆë‹¤.
            
        - ($\tanh$ëŠ” ReLUë‚˜ ì‹œê·¸ëª¨ì´ë“œ ê°™ì€ í™œì„±í™” í•¨ìˆ˜ìž…ë‹ˆë‹¤.)
            
    - $y_t = W_{hy} h_t + b_y$
        
        - (í•„ìš”í•˜ë‹¤ë©´) ê° ë‹¨ê³„ì˜ 'ê¸°ì–µ' $h_t$ë¥¼ ì´ìš©í•´ ì˜ˆì¸¡ $y_t$ë¥¼ ë§Œë“­ë‹ˆë‹¤.
            

**3. PyTorchì˜ `nn.RNN` ë ˆì´ì–´**

- ì´ ë³µìž¡í•œ ë£¨í”„ ê³„ì‚°ì„ PyTorchëŠ” `nn.RNN`ì´ë¼ëŠ” ë ˆì´ì–´ í•˜ë‚˜ë¡œ íŽ¸ë¦¬í•˜ê²Œ ì œê³µí•©ë‹ˆë‹¤.
    
- **ì£¼ìš” íŒŒë¼ë¯¸í„°:**
    
    - `input_size`: ìž…ë ¥ ë°ì´í„° 1ê°œ(ì‹œí€€ìŠ¤ì˜ 1ê°œ ìš”ì†Œ)ê°€ ëª‡ ê°œì˜ ìˆ«ìžë¡œ ì´ë£¨ì–´ì ¸ ìžˆëŠ”ì§€. (ì˜ˆ: ì›-í•« ì¸ì½”ë”©ëœ ë‹¨ì–´ì˜ ì°¨ì›)
        
    - `hidden_size`: 'ê¸°ì–µ' $h_t$ë¥¼ ëª‡ ê°œì˜ ìˆ«ìžë¡œ ì €ìž¥í• ì§€ (ì€ë‹‰ ìƒíƒœì˜ ì°¨ì›, ì¦‰ ë‰´ëŸ° ìˆ˜).
        
    - `batch_first=True`: **(í•„ìˆ˜ ê¶Œìž¥!)** ìž…ë ¥ í…ì„œì˜ ìˆœì„œë¥¼ `(ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, input_size)`ë¡œ ë‹¤ë£° ìˆ˜ ìžˆê²Œ í•´ì£¼ëŠ” íŽ¸ë¦¬í•œ ì˜µì…˜ìž…ë‹ˆë‹¤.


RNNì˜ ê°€ìž¥ ì¼ë°˜ì ì¸ í™œìš© í˜•íƒœ ì¤‘ í•˜ë‚˜ì¸ **"Many-to-One"** ë¬¸ì œë¥¼ í’€ì–´ë³´ê² ìŠµë‹ˆë‹¤.

- **ë¬¸ì œ:** ì—¬ëŸ¬ ê°œì˜ ìˆœì°¨ì ì¸ ë°ì´í„°(Many)ë¥¼ ë³´ê³ , ë§ˆì§€ë§‰ì— **í•˜ë‚˜ì˜** ê²°ë¡ (One)ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    
- **ì˜ˆì‹œ:** `[8, 1, 5, 3]` ìˆœì„œ $\rightarrow$ `Class 0 (ìŒìˆ˜ íŒ¨í„´)`, `[2, 7, 4, 9]` ìˆœì„œ $\rightarrow$ `Class 1 (ì–‘ìˆ˜ íŒ¨í„´)`ì„ ë¶„ë¥˜í•˜ëŠ” (ê°€ìƒì˜) ë¬¸ì œ.

```python
import torch
import torch.nn as nn
import torch.optim as optim

# --- 0. ë°ì´í„° ì¤€ë¹„ ---
# [Batch, Sequence Length, Input_dim]
# 2ê°œì˜ ë°ì´í„° ìƒ˜í”Œ, ê° ìƒ˜í”Œì€ 4ê°œì˜ ì‹œí€€ìŠ¤(ìˆœì„œ), ê° ì‹œí€€ìŠ¤ ìš”ì†ŒëŠ” 1ê°œì˜ íŠ¹ì„±
x_train = torch.tensor([
    [[8.0], [1.0], [5.0], [3.0]],  # Sample 1 (Class 0)
    [[2.0], [7.0], [4.0], [9.0]]   # Sample 2 (Class 1)
])
# y_train (ê° ìƒ˜í”Œì˜ ìµœì¢… ì •ë‹µ)
y_train = torch.tensor([[0.0], [1.0]]) # Sample 1 -> 0, Sample 2 -> 1

# --- í•˜ì´í¼íŒŒë¼ë¯¸í„° ---
input_size = 1   # ìž…ë ¥ 1ê°œ(ì˜ˆ: 8.0)ì˜ ì°¨ì›
hidden_size = 5  # 'ê¸°ì–µ(hidden state)'ì˜ í¬ê¸°
num_layers = 1   # RNN ì¸µì„ 1ê°œë§Œ ìŒ“ìŒ
output_size = 1  # ìµœì¢… ì¶œë ¥ (0 ë˜ëŠ” 1)

# --- 1. ëª¨ë¸ ì •ì˜ (class ì‚¬ìš©) ---
class SimpleRNNModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):
        super().__init__()
        self.hidden_dim = hidden_dim
        self.layer_dim = layer_dim
        
        # 1. RNN ë ˆì´ì–´ ì •ì˜
        # batch_first=True: ìž…ë ¥ í…ì„œ ìˆœì„œë¥¼ (batch_size, seq_length, input_size)ë¡œ
        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True)
        
        # 2. ìµœì¢… ì¶œë ¥ì„ ìœ„í•œ Linear ë ˆì´ì–´ (Many-to-One)
        # RNNì˜ ë§ˆì§€ë§‰ 'ê¸°ì–µ(hidden state)'ì„ ë°›ì•„ì„œ 1ê°œì˜ ì¶œë ¥ìœ¼ë¡œ
        self.fc = nn.Linear(hidden_dim, output_dim)
        
        # 3. ì¶œë ¥ì„ 0~1 ì‚¬ì´ í™•ë¥ ë¡œ
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        # 1. ì´ˆê¸° ì€ë‹‰ ìƒíƒœ(h_0)ë¥¼ 0ìœ¼ë¡œ ì´ˆê¸°í™”
        # (layer_dim, batch_size, hidden_dim)
        # x.size(0)ì€ ë°°ì¹˜ í¬ê¸°(ì—¬ê¸°ì„œëŠ” 2)
        h_0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)
        
        # 2. RNN ì‹¤í–‰
        # rnn_out: ëª¨ë“  ì‹œí€€ìŠ¤ ë‹¨ê³„(4ê°œ)ì˜ hidden state ì¶œë ¥
        # h_n:    ë§ˆì§€ë§‰ ë‹¨ê³„(t=4)ì˜ hidden state (ê¸°ì–µ)
        rnn_out, h_n = self.rnn(x, h_0)
        
        # 3. Many-to-One: ìš°ë¦¬ëŠ” ë§ˆì§€ë§‰ 'ê¸°ì–µ' h_në§Œ í•„ìš”
        # h_nì˜ shape: (num_layers, batch_size, hidden_size) -> (1, 2, 5)
        # [0]ì„ í†µí•´ (batch_size, hidden_size)ë¡œ ë³€ê²½ -> (2, 5)
        h_n_last = h_n[0] 
        
        # 4. Linear ë ˆì´ì–´ í†µê³¼
        out = self.fc(h_n_last)
        
        # 5. Sigmoid í™œì„±í™”
        out = self.sigmoid(out)
        
        return out

# ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤(ê°ì²´) ìƒì„±
model = SimpleRNNModel(input_size, hidden_size, num_layers, output_size)

# --- 2. ì†ì‹¤ í•¨ìˆ˜(Loss) ë° ì˜µí‹°ë§ˆì´ì €(Optimizer) ì •ì˜ ---
criterion = nn.BCELoss() # ë°”ì´ë„ˆë¦¬ ë¶„ë¥˜
optimizer = optim.SGD(model.parameters(), lr=0.1)

# --- 3. í•™ìŠµ(Training) ì‹¤í–‰ ---
epochs = 500

for epoch in range(epochs + 1):
    prediction = model(x_train)
    loss = criterion(prediction, y_train)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    if epoch % 50 == 0:
        predicted_classes = (prediction >= 0.5).float()
        accuracy = (predicted_classes == y_train).float().mean()
        print(f'Epoch {epoch:4d}/{epochs} | Loss: {loss.item():.6f} | Accuracy: {accuracy.item() * 100:.2f}%')

# --- 4. í•™ìŠµ ê²°ê³¼ í™•ì¸ ---
print("\n--- í•™ìŠµ ì™„ë£Œ í›„ ---")
final_prediction = (model(x_train) >= 0.5).float()
for i in range(len(x_train)):
    print(f"Input: {x_train[i].view(-1).tolist()} | ì •ë‹µ: {y_train[i].item()} | ì˜ˆì¸¡: {final_prediction[i].item()}")
```